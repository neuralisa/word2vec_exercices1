{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given neural network code, we work with tensors that must have compatible dimensions for matrix operations. Here's how these dimensions play out:\n",
    "\n",
    "- `X` is the input tensor with dimensions 3, representing the features input to the network.\n",
    "- `W1` is the weight matrix for the first layer, with dimensions 2x3, enabling the transformation of `X` (3-dimensional) into a 2-dimensional hidden layer vector `H`.\n",
    "- `b1` is the bias for the first layer, a 2-dimensional vector, added to the output of `W1 * X` to complete the layer computation.\n",
    "- `W2` is the weight vector for the second layer, with 2 elements, used to transform the hidden layer vector `H` into the scalar output `Y_pred`.\n",
    "- `b2` is the scalar bias for the output layer.\n",
    "\n",
    "The forward pass of the network involves multiplying and adding these tensors to compute the loss between the predicted output `Y_pred` and the true output `Y_true`. This process is mathematically represented and executed using PyTorch's tensor operations.\n",
    "\n",
    "In the background, PyTorch builds a computation graph during the forward pass. This graph records the operations and tensors involved, allowing for the automatic computation of gradients during the backward pass (not shown here but invoked with `loss.backward()`). This automatic differentiation feature is crucial for training neural networks, as it efficiently calculates the gradients needed to adjust the weights during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#%% PyTorch version\n",
    "# Initialize variables\n",
    "X = torch.tensor([1.5, 2.0, 3.0], requires_grad=True)\n",
    "Y_true = torch.tensor([0.0])\n",
    "W1 = torch.tensor([[0.9, -0.2, 0.1], [0.5, 0.3, -0.7]], requires_grad=True)  # 2x3 matrix\n",
    "b1 = torch.tensor([0.1, -0.1], requires_grad=True)  # 2-element vector\n",
    "W2 = torch.tensor([0.3, -0.5], requires_grad=True)  # 2-element vector to match H\n",
    "b2 = torch.tensor([0.1], requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "start_time = time.time()\n",
    "H = torch.matmul(W1, X) + b1\n",
    "Y_pred = torch.dot(W2, H) + b2\n",
    "loss = 0.5 * (Y_true - Y_pred) ** 2\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "print(f\"PyTorch Loss: {loss.item()}, dW1: {W1.grad}, dW2: {W2.grad}\")\n",
    "torch_time = time.time() - start_time\n",
    "print(f\"PyTorch computation time: {torch_time} seconds\")\n",
    "\n",
    "#%% Numpy version\n",
    "# Initialize variables\n",
    "X_np = np.array([1.5, 2.0, 3.0])\n",
    "Y_true_np = np.array([0.0])\n",
    "W1_np = np.array([[0.9, -0.2, 0.1], [0.5, 0.3, -0.7]])  # 2x3 matrix\n",
    "b1_np = np.array([0.1, -0.1])\n",
    "W2_np = np.array([0.3, -0.5])  # 2-element vector\n",
    "b2_np = np.array([0.1])\n",
    "\n",
    "# Forward pass\n",
    "start_time = time.time()\n",
    "H_np = np.dot(W1_np, X_np) + b1_np\n",
    "Y_pred_np = np.dot(W2_np, H_np) + b2_np\n",
    "loss_np = 0.5 * (Y_true_np - Y_pred_np) ** 2\n",
    "\n",
    "# Backward pass (manually computed gradients)\n",
    "dY_pred_np = Y_pred_np - Y_true_np\n",
    "dW2_np = dY_pred_np * H_np\n",
    "dH_np = dY_pred_np * W2_np\n",
    "dW1_np = np.outer(dH_np, X_np)\n",
    "\n",
    "print(f\"Numpy Loss: {loss_np}, dW1: {dW1_np}, dW2: {dW2_np}\")\n",
    "numpy_time = time.time() - start_time\n",
    "print(f\"Numpy computation time: {numpy_time} seconds\")\n",
    "\n",
    "# Compare speed\n",
    "print(f\"Speedup using PyTorch: {numpy_time / torch_time}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Loss: 8394926.0\n",
      "PyTorch computation time: 0.0025353431701660156 seconds\n",
      "Numpy Loss: 3898473.7981619933\n",
      "Numpy computation time: 0.0013637542724609375 seconds\n",
      "Speedup using PyTorch: 0.5378973105134475x\n"
     ]
    }
   ],
   "source": [
    "#%% Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#%% PyTorch version with larger matrices\n",
    "# Initialize variables with larger random matrices\n",
    "input_size, hidden_size, output_size = 10000, 500, 10\n",
    "X = torch.randn(input_size, requires_grad=True)\n",
    "Y_true = torch.randn(output_size)\n",
    "W1 = torch.randn(hidden_size, input_size, requires_grad=True)\n",
    "b1 = torch.randn(hidden_size, requires_grad=True)\n",
    "W2 = torch.randn(output_size, hidden_size, requires_grad=True)\n",
    "b2 = torch.randn(output_size, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "start_time = time.time()\n",
    "H = torch.matmul(W1, X) + b1\n",
    "Y_pred = torch.matmul(W2, H) + b2\n",
    "loss = torch.nn.functional.mse_loss(Y_pred, Y_true)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "torch_time = time.time() - start_time\n",
    "print(f\"PyTorch Loss: {loss.item()}\")\n",
    "print(f\"PyTorch computation time: {torch_time} seconds\")\n",
    "\n",
    "#%% Numpy version with larger matrices\n",
    "# Initialize variables with larger random matrices\n",
    "X_np = np.random.randn(input_size)\n",
    "Y_true_np = np.random.randn(output_size)\n",
    "W1_np = np.random.randn(hidden_size, input_size)\n",
    "b1_np = np.random.randn(hidden_size)\n",
    "W2_np = np.random.randn(output_size, hidden_size)\n",
    "b2_np = np.random.randn(output_size)\n",
    "\n",
    "# Forward pass\n",
    "start_time = time.time()\n",
    "H_np = np.dot(W1_np, X_np) + b1_np\n",
    "Y_pred_np = np.dot(W2_np, H_np) + b2_np\n",
    "loss_np = np.mean((Y_pred_np - Y_true_np) ** 2)\n",
    "\n",
    "numpy_time = time.time() - start_time\n",
    "print(f\"Numpy Loss: {loss_np}\")\n",
    "print(f\"Numpy computation time: {numpy_time} seconds\")\n",
    "\n",
    "# Compare speed\n",
    "print(f\"Speedup using PyTorch: {numpy_time / torch_time}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
